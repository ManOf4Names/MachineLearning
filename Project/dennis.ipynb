{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import sklearn.cluster as skc\n",
    "import sklearn.neighbors as skn\n",
    "import sklearn.feature_selection as skf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kicked Tensorflow to it's own cell so I can work on K-Means at work\n",
    "import tensorflow as tf\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/data.csv', header=0)\n",
    "genreKey = {\"blues\": 0,\n",
    "            \"classical\": 1,\n",
    "            \"country\": 2,\n",
    "            \"disco\": 3,\n",
    "            \"hiphop\": 4,\n",
    "            \"jazz\": 5,\n",
    "            \"metal\": 6,\n",
    "            \"pop\": 7,\n",
    "            \"reggae\": 8,\n",
    "            \"rock\": 9}\n",
    "\n",
    "def dimReduce(data, dims=10):\n",
    "    # Select Data\n",
    "    X = np.array(data.iloc[:, 1:29])\n",
    "    y = np.array(data.iloc[:, 29])\n",
    "    # Make the feature selection model with ANOVA F Measure\n",
    "    fs = skf.SelectKBest(score_func=skf.f_classif, k=dims)\n",
    "    # Run the data through selection to obtain final set\n",
    "    X_sel = fs.fit_transform(X, y)\n",
    "\n",
    "    return X_sel, y\n",
    "\n",
    "def prepData(data, key, split=0.2, dims= 10, doSplit=True):\n",
    "    # Reduce the dimensionality of the dataset to a set number of features\n",
    "    x, y = dimReduce(data, dims)\n",
    "    # Define the number of elements in the test set\n",
    "    splitRange = int(len(data) * split)\n",
    "    # Create and randomize an array representing data ordering\n",
    "    rand = [i for i in range(len(data))]\n",
    "    rd.shuffle(rand)\n",
    "    # Create Testing and training arrays\n",
    "    x_train = np.array([])\n",
    "    y_train = np.array([])\n",
    "    x_test = np.array([])\n",
    "    y_test = np.array([])\n",
    "\n",
    "    # Populate test arrays with a random split% of the whole set\n",
    "    for i in range(splitRange):\n",
    "        # Set the dimensions of the x_test array\n",
    "        if x_test.ndim == 1:\n",
    "            x_test = np.array([x[rand[i]]])\n",
    "        # Append further elements to the existing array\n",
    "        else:\n",
    "            x_test = np.append(x_test, [x[rand[i]]], 0)\n",
    "        # Add label in integer form\n",
    "        y_test = np.append(y_test, key[y[rand[i]]])\n",
    "            \n",
    "    for i in range(splitRange, len(data)):\n",
    "        # Set the dimensions of the x_train array\n",
    "        if x_train.ndim == 1:\n",
    "            x_train = np.array([x[rand[i]]])\n",
    "        # Append further elements to the existing array\n",
    "        else:\n",
    "            x_train = np.append(x_train, [x[rand[i]]], 0)\n",
    "        # Add label in integer form\n",
    "        y_train = np.append(y_train, key[y[rand[i]]])\n",
    "\n",
    "    if (doSplit):\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    else:\n",
    "        return np.concatenate((x_train, x_test)), np.concatenate((y_train, y_test))\n",
    "\n",
    "def normalize(data):\n",
    "    # Array for the max value of each feature. Used in normalization\n",
    "    normax = []\n",
    "    # Array for the min value of each feature. Used to eliminate negatives\n",
    "    normin = []\n",
    "\n",
    "    # Populate max and min arrays\n",
    "    for i in range(data.shape[1]):\n",
    "        normin.append(min(data[:, i]))\n",
    "        normax.append(max(data[:, i]) - normin[i])\n",
    "\n",
    "    # Normalize each vector in the dataset\n",
    "    for i in data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = (i[j] - normin[j]) / normax[j]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Split the dataset into test and training sets.\n",
    "x_train, y_train, x_test, y_test = prepData(data, genreKey, dims=10)\n",
    "x_train = normalize(x_train)\n",
    "x_test = normalize(x_test)\n",
    "\n",
    "# Unsplit Data for K-Means\n",
    "x, y = prepData(data, genreKey, doSplit=False)\n",
    "x = normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9999999999999998, 0.0)\n",
      "(0.9661792458636241, 0.0)\n",
      "(0.030639801277409725, 0.3330788293383985)\n",
      "(-0.043502602880983315, 0.1692544723846814)\n",
      "(-0.014414866668119046, 0.6488994417960553)\n",
      "(-0.039282894697534605, 0.21454679775808225)\n",
      "(-0.020564005586567322, 0.5159853253511273)\n",
      "(0.01993501140303672, 0.5289075503626313)\n",
      "(0.011270745777701131, 0.721857182891039)\n",
      "(0.007200247933076398, 0.8201049443408729)\n",
      "(-0.09749065571404361, 0.0020257967559981463)\n",
      "(0.029352104434754847, 0.3538050999922622)\n",
      "(-0.08222328572652084, 0.009287600931363367)\n",
      "(0.04389417431185186, 0.16544538885393623)\n",
      "(-0.0835002826359111, 0.0082461155876586)\n",
      "(0.03726840531078745, 0.23900975992651552)\n",
      "(-0.07358766226569352, 0.019949748873707828)\n",
      "(0.032041307867512706, 0.31142917224717104)\n",
      "(-0.07877825420550125, 0.012704572180658513)\n",
      "(-0.028214950721507037, 0.37277007741300466)\n",
      "(-0.04541542425132927, 0.15125686964414928)\n",
      "(0.010451690561105958, 0.7413190275630325)\n",
      "(-0.05512661030706501, 0.08143826466678177)\n",
      "(0.024411420480320703, 0.44064392471792907)\n",
      "(-0.0762078106138853, 0.015935285099912887)\n",
      "(-0.010241887670331016, 0.7463315014512125)\n",
      "(-0.061398690280219145, 0.05225826079788826)\n",
      "(-0.027405020527307564, 0.38665385962946675)\n",
      "(1.0, 0.0)\n",
      "(0.08068397864858814, 0.010697669037143835)\n",
      "(0.004606723011160417, 0.8843193185963714)\n",
      "(0.035842830771540844, 0.2574679568152075)\n",
      "(0.011286843824723761, 0.7214764197429098)\n",
      "(0.03348859305642012, 0.2900670544970253)\n",
      "(0.05651653794413311, 0.07403411087874007)\n",
      "(0.08215608177589286, 0.009345522645691391)\n",
      "(-0.041054810399789164, 0.1945657356234452)\n",
      "(-0.09986870157630452, 0.0015664442822161339)\n",
      "(0.06351800855633966, 0.0446293082117501)\n",
      "(-0.09542230713907306, 0.002522417306861292)\n",
      "(0.08804791557380255, 0.0053321742005514915)\n",
      "(-0.08028858798555158, 0.011089247306326357)\n",
      "(0.08282915902405447, 0.008779680388109007)\n",
      "(-0.07728945785204423, 0.01449694533338968)\n",
      "(0.07697073766949433, 0.014908397968987972)\n",
      "(-0.07545646538345749, 0.017006759192358143)\n",
      "(0.015129005907856938, 0.6327568634772134)\n",
      "(-0.05276799033104317, 0.09536629555822361)\n",
      "(0.05007508485706477, 0.11352964395070717)\n",
      "(-0.06369473476989039, 0.044037868344384355)\n",
      "(0.04410897704629047, 0.1633834026205844)\n",
      "(-0.0937702047086383, 0.0029963961383903414)\n",
      "(0.006229270299978545, 0.8440291620657847)\n",
      "(-0.07837234541468303, 0.013172716777729767)\n",
      "(-0.027907136750879663, 0.3780098785621599)\n",
      "(1.0, 0.0)\n",
      "(0.4995769771412873, 3.02053874293626e-64)\n",
      "(0.6155235278339611, 2.5742877301189425e-105)\n",
      "(0.5174820482766862, 1.383799007870868e-69)\n",
      "(0.5979100297990985, 5.6853731657918964e-98)\n",
      "(0.5547349176520501, 9.003880683504389e-82)\n",
      "(0.6592941508651425, 9.589735989744386e-126)\n",
      "(-0.5984951414489492, 3.2967903071000316e-98)\n",
      "(-0.05443140472382363, 0.08536069805851164)\n",
      "(0.26422552669432176, 1.9532246875721493e-17)\n",
      "(-0.01011556921316072, 0.7493546122025839)\n",
      "(0.41695347496606383, 2.468770166204374e-43)\n",
      "(0.06753596794707895, 0.03272491141649023)\n",
      "(0.5098291874461499, 2.8971450046328056e-67)\n",
      "(0.1157205914247312, 0.0002452633662851144)\n",
      "(0.48937985976154774, 2.409110990637289e-61)\n",
      "(0.07266843562278133, 0.02155368167792863)\n",
      "(0.5166204085947175, 2.543006328414578e-69)\n",
      "(-0.08172500867839691, 0.009724767926108708)\n",
      "(0.41716089688545077, 2.2226852622848995e-43)\n",
      "(-0.14345535303320153, 5.254568846403962e-06)\n",
      "(0.33239607897147677, 3.1925770394486288e-27)\n",
      "(-0.16344957097159726, 2.0225378348007984e-07)\n",
      "(0.26979071580440117, 3.8765172589839815e-18)\n",
      "(-0.08990598565549997, 0.00443717341482603)\n",
      "(0.2817746403474032, 1.0461626130127168e-19)\n",
      "(1.0, 0.0)\n",
      "(0.5099843994039335, 2.6030556931012904e-67)\n",
      "(0.5297678741112126, 1.94559662256297e-73)\n",
      "(0.5377181950481765, 5.1362150035564535e-76)\n",
      "(0.3321191546453092, 3.542627581915379e-27)\n",
      "(0.8072597848690927, 8.902049707846689e-231)\n",
      "(-0.4837651435692409, 8.674683603083741e-60)\n",
      "(0.13933891930538803, 9.762746026280159e-06)\n",
      "(0.008695454976030376, 0.7835961311779487)\n",
      "(0.10870011923637922, 0.0005746449298863901)\n",
      "(0.1257823574725227, 6.6502812875855e-05)\n",
      "(0.1675919610616762, 9.775893294595507e-08)\n",
      "(0.1789999617139941, 1.2016748663206967e-08)\n",
      "(0.21604113819186796, 5.021112729547776e-12)\n",
      "(0.18602526296591104, 3.083560044663251e-09)\n",
      "(0.11740987913018362, 0.0001983887085038872)\n",
      "(0.18331045650331565, 5.248940379020086e-09)\n",
      "(0.012818309423575813, 0.6855802838204645)\n",
      "(0.16306481829754144, 2.16184762373462e-07)\n",
      "(-0.011242508275945137, 0.7225252437654115)\n",
      "(0.0838268395623179, 0.007997125648217768)\n",
      "(-0.029600554139284453, 0.34974404731679615)\n",
      "(0.11825282527829041, 0.0001782764009872783)\n",
      "(0.03151686095157787, 0.3194195206325815)\n",
      "(0.12482682895861447, 7.5604112264901e-05)\n",
      "(0.9999999999999999, 0.0)\n",
      "(0.9044381706706398, 0.0)\n",
      "(0.9796333818926218, 0.0)\n",
      "(0.8747553687304833, 2.76315165e-316)\n",
      "(0.7208307176542152, 4.627178941358915e-161)\n",
      "(-0.9401711289696061, 0.0)\n",
      "(0.18799926965810618, 2.0839926727410144e-09)\n",
      "(-0.13683855631316574, 1.4103495958193722e-05)\n",
      "(0.06903244877100649, 0.029045249560108632)\n",
      "(0.017571601893570474, 0.5788873336787875)\n",
      "(0.21574364321646147, 5.377415084141724e-12)\n",
      "(0.1343474516910192, 2.0218575166776923e-05)\n",
      "(0.2887831021150621, 1.1636252327292939e-20)\n",
      "(0.1928505813491804, 7.81451307911387e-10)\n",
      "(0.15274893278376617, 1.2172543734664028e-06)\n",
      "(0.17494581781643645, 2.5716322160337044e-08)\n",
      "(0.051260014902897395, 0.10522761618502154)\n",
      "(0.17068920217831526, 5.609669878841408e-08)\n",
      "(0.022393032627577896, 0.47935963132029763)\n",
      "(0.15367779666248477, 1.046576707267794e-06)\n",
      "(0.02740313740571478, 0.3866865027882325)\n",
      "(0.2280483124968484, 2.901583535196664e-13)\n",
      "(0.02776122963676185, 0.3805093482653858)\n",
      "(0.26959822492865715, 4.102129719572295e-18)\n",
      "(1.0, 0.0)\n",
      "(0.9561939534690728, 0.0)\n",
      "(0.6123248445045619, 6.010360572634596e-104)\n",
      "(0.6483726317402717, 2.4873634177772843e-120)\n",
      "(-0.8966597304631556, 0.0)\n",
      "(0.4940517333235098, 1.160275562046257e-62)\n",
      "(-0.2796360448126487, 2.0196523945700302e-19)\n",
      "(0.30295520562154327, 1.1313262980044873e-22)\n",
      "(-0.06609772812566309, 0.03662991413348121)\n",
      "(0.39108532502658927, 6.836225403247108e-38)\n",
      "(0.027736262141581706, 0.38093806885303644)\n",
      "(0.4095725111619186, 9.875246372495759e-42)\n",
      "(0.06343159757069904, 0.044920922022522014)\n",
      "(0.289571775995933, 9.05284363582574e-21)\n",
      "(0.03807827095976972, 0.22894887191677848)\n",
      "(0.20527220410622463, 5.636861767350858e-11)\n",
      "(0.054739524627041534, 0.08360382777499661)\n",
      "(0.12764945669957994, 5.162349819457619e-05)\n",
      "(0.027061709725626437, 0.3926327355625485)\n",
      "(0.10491352964479496, 0.0008915680667643304)\n",
      "(0.11462398399179573, 0.0002810449981049933)\n",
      "(0.09815073703261695, 0.0018872645960648592)\n",
      "(0.18793205365898594, 2.1121283024486073e-09)\n",
      "(0.9999999999999997, 0.0)\n",
      "(0.7798085381670862, 3.1893714256946283e-205)\n",
      "(0.7217456210308377, 1.171034615150069e-161)\n",
      "(-0.9343053746651535, 0.0)\n",
      "(0.2955898540711063, 1.298464546510746e-21)\n",
      "(-0.156113905777484, 7.012111308445246e-07)\n",
      "(0.12420752172873278, 8.211799407105613e-05)\n",
      "(0.034629322030305776, 0.27394014864671207)\n",
      "(0.24970421977617036, 1.112674508250567e-15)\n",
      "(0.13761799259859112, 1.2584109498016176e-05)\n",
      "(0.3110730436957127, 7.074133401787411e-24)\n",
      "(0.1849448383011885, 3.814229610382919e-09)\n",
      "(0.17394021620410946, 3.097328103888842e-08)\n",
      "(0.16282699969277922, 2.2525383584928375e-07)\n",
      "(0.08173830096644438, 0.009712872114716144)\n",
      "(0.15857210889309073, 4.651899682759621e-07)\n",
      "(0.03214642997922518, 0.3098435298427564)\n",
      "(0.13232631915047116, 2.6956306282193757e-05)\n",
      "(0.03962417876693211, 0.21058770147648212)\n",
      "(0.20500969105388187, 5.969468173365408e-11)\n",
      "(0.04812063488819738, 0.1283386914776381)\n",
      "(0.256643743865596, 1.6640180143055221e-16)\n",
      "(0.9999999999999998, 0.0)\n",
      "(0.6341393293799357, 1.3342507661638918e-113)\n",
      "(-0.7601266873507413, 4.554783010598945e-189)\n",
      "(-0.17988310224625864, 1.015768475331787e-08)\n",
      "(-0.007672320239726244, 0.808532073878355)\n",
      "(-0.20104463385999677, 1.405928224439702e-10)\n",
      "(0.06950681605480973, 0.027955659763908305)\n",
      "(-0.03058365906843958, 0.33396582407641356)\n",
      "(0.19750948932461262, 2.9736124685345094e-10)\n",
      "(0.07515875792992065, 0.01744846703400252)\n",
      "(0.27579717895978356, 6.483879292661751e-19)\n",
      "(-0.044591288347575704, 0.15882404988261686)\n",
      "(0.2630462759653412, 2.7381455675647924e-17)\n",
      "(-0.14204984432192239, 6.504901478000662e-06)\n",
      "(0.2406979701577553, 1.202910117959066e-14)\n",
      "(-0.10706945574458925, 0.0006954877314330854)\n",
      "(0.249473887727015, 1.1839386089139451e-15)\n",
      "(-0.07688547210076768, 0.015020199045210517)\n",
      "(0.29715202232056775, 7.783935364580114e-22)\n",
      "(-0.0745795819024658, 0.0183366405390724)\n",
      "(0.30503099586475446, 5.614767449295372e-23)\n",
      "(0.9999999999999999, 0.0)\n",
      "(-0.6389109253723498, 8.107332044742617e-116)\n",
      "(-0.10107785585710903, 0.0013715856705936978)\n",
      "(0.10867625567360653, 0.0005762629915887544)\n",
      "(-0.11474642419783437, 0.0002768202237769895)\n",
      "(0.23565683601732623, 4.373553989548488e-14)\n",
      "(0.007180885531277395, 0.8205804688961575)\n",
      "(0.3316640636820679, 4.202225807011558e-27)\n",
      "(0.05341712409797244, 0.09135547576491697)\n",
      "(0.34028416965517483, 1.5758388763497686e-28)\n",
      "(-0.027020796728544984, 0.3933489625380407)\n",
      "(0.33161896200513813, 4.2738726499619305e-27)\n",
      "(-0.1716973850588465, 4.671597688734322e-08)\n",
      "(0.25220647367127497, 5.645481563760901e-16)\n",
      "(-0.20078745449938395, 1.485361448657094e-10)\n",
      "(0.1856590549118149, 3.3144941244438793e-09)\n",
      "(-0.20850270825258715, 2.7663513695617394e-11)\n",
      "(0.19976903630950715, 1.845187455175533e-10)\n",
      "(-0.12157775184146831, 0.00011614533416568)\n",
      "(0.19535160355502199, 4.665798192025579e-10)\n",
      "(0.9999999999999996, 0.0)\n",
      "(-0.2688410389125503, 5.1222046516082204e-18)\n",
      "(0.049740463116792005, 0.11596508634104712)\n",
      "(-0.15230337353814152, 1.3083248943668812e-06)\n",
      "(-0.09258723699866059, 0.0033841674672024226)\n",
      "(-0.2640853749864382, 2.033416345680206e-17)\n",
      "(-0.19208490386063762, 9.138542245694453e-10)\n",
      "(-0.32257507333053426, 1.1979660114721945e-25)\n",
      "(-0.21632922222134998, 4.698149523619502e-12)\n",
      "(-0.2039103902487835, 7.582951142641177e-11)\n",
      "(-0.1769903661608466, 1.7560144449909348e-08)\n",
      "(-0.11056702898875696, 0.0004603807782254483)\n",
      "(-0.19579041243140943, 4.25914000602198e-10)\n",
      "(-0.064464679492126, 0.0415376630538522)\n",
      "(-0.16030462372837165, 3.4703909623270575e-07)\n",
      "(-0.05106371544732682, 0.1065687042264841)\n",
      "(-0.20259383448018659, 1.0081107615866729e-10)\n",
      "(-0.027793446695049524, 0.37995658189502274)\n",
      "(-0.2386507874983263, 2.0391424909213982e-14)\n",
      "(1.0, 0.0)\n",
      "(-0.4096023572653601, 9.730835929974545e-42)\n",
      "(0.6013004017611967, 2.380113672223353e-99)\n",
      "(-0.2557655524641595, 2.123120299065648e-16)\n",
      "(0.5191268585525217, 4.310027856393473e-70)\n",
      "(-0.3171573140489191, 8.363491763984381e-25)\n",
      "(0.4386845544076383, 2.737942120906246e-48)\n",
      "(-0.34724667685309046, 1.0290256099015134e-29)\n",
      "(0.42734393385662367, 1.1705581534747596e-45)\n",
      "(-0.3386987384682221, 2.905250316288455e-28)\n",
      "(0.4250210612741213, 3.935902030221056e-45)\n",
      "(-0.26285901440583676, 2.888584097900801e-17)\n",
      "(0.2986279476392791, 4.786027409011015e-22)\n",
      "(-0.2980560972247478, 5.780429532740677e-22)\n",
      "(0.2504008389087997, 9.21848889270241e-16)\n",
      "(-0.19098688290124466, 1.1425397835439903e-09)\n",
      "(0.23007574924872254, 1.763975935721024e-13)\n",
      "(-0.07697355778590256, 0.014904712744352901)\n",
      "(0.9999999999999999, 0.0)\n",
      "(-0.4489995404445615, 9.040678485856676e-51)\n",
      "(0.6735561301649811, 3.633475532087851e-133)\n",
      "(-0.43269330344211976, 6.915440042138606e-47)\n",
      "(0.6383541012907205, 1.4775503976125573e-115)\n",
      "(-0.45107786996552146, 2.791634445824983e-51)\n",
      "(0.5490755373560376, 8.047353861082087e-80)\n",
      "(-0.38019942472240525, 9.647971196751924e-36)\n",
      "(0.582581449960881, 6.095906911506946e-92)\n",
      "(-0.4591858812201753, 2.6352889758388003e-53)\n",
      "(0.4499238499848702, 5.366225429412846e-51)\n",
      "(-0.44189171606000877, 4.732438763246763e-49)\n",
      "(0.4083419579477478, 1.8103573786780755e-41)\n",
      "(-0.4058259526617461, 6.201874432149522e-41)\n",
      "(0.15141658034547584, 1.5094347127195314e-06)\n",
      "(-0.278503847724525, 2.8543563265892123e-19)\n",
      "(0.09773358287473763, 0.001973764657755625)\n",
      "(1.0, 0.0)\n",
      "(-0.4346828476561062, 2.383609895894026e-47)\n",
      "(0.7663123500009033, 5.668727339066632e-194)\n",
      "(-0.4217718251754139, 2.112765874984466e-44)\n",
      "(0.6473948567824216, 7.406019208720683e-120)\n",
      "(-0.4463333732906954, 4.034021398656284e-50)\n",
      "(0.6408931854837743, 9.474024923024293e-117)\n",
      "(-0.4601681354097517, 1.4851748580454983e-53)\n",
      "(0.6315144746933495, 2.1276542506908926e-112)\n",
      "(-0.3753531890232226, 8.232864566012998e-35)\n",
      "(0.5329765326990246, 1.8059309370928607e-74)\n",
      "(-0.3409769414461688, 1.2048655263336676e-28)\n",
      "(0.3592046169123743, 8.056447892891951e-32)\n",
      "(-0.30460644057546266, 6.48276676403982e-23)\n",
      "(0.3356952307980349, 9.16777717727185e-28)\n",
      "(-0.13531619512297546, 1.7589141533973747e-05)\n",
      "(1.0, 0.0)\n",
      "(-0.48211324830702335, 2.458518646518329e-59)\n",
      "(0.8372940006140809, 6.233509929660537e-264)\n",
      "(-0.4468231132884029, 3.068025262169042e-50)\n",
      "(0.7241824666486923, 2.933372996716088e-163)\n",
      "(-0.427879829723838, 8.837054425283526e-46)\n",
      "(0.7149651300626663, 2.723059021564968e-157)\n",
      "(-0.47541110882953574, 1.5887631065994225e-57)\n",
      "(0.5670965914477645, 3.627408722790285e-86)\n",
      "(-0.4797537690833078, 1.0779713208442032e-58)\n",
      "(0.4577538244490484, 6.060014878066266e-53)\n",
      "(-0.4052063774615409, 8.385089205362102e-41)\n",
      "(0.30194694657269006, 1.5866693410085284e-22)\n",
      "(-0.32956260821871447, 9.210373441029668e-27)\n",
      "(0.14379547160318096, 4.988521768367018e-06)\n",
      "(0.9999999999999997, 0.0)\n",
      "(-0.48729489430490636, 9.187353920921338e-61)\n",
      "(0.7870061243879942, 1.486300786804212e-211)\n",
      "(-0.42297143069798304, 1.1385155691100115e-44)\n",
      "(0.7214415834385205, 1.8498836353855234e-161)\n",
      "(-0.428240736535052, 7.310773958552196e-46)\n",
      "(0.6821460973010404, 7.681216339286618e-138)\n",
      "(-0.3320261932606469, 3.6684539570306666e-27)\n",
      "(0.6011910717123039, 2.6381387101012173e-99)\n",
      "(-0.2984097529558434, 5.143740364406594e-22)\n",
      "(0.49117293170713044, 7.562878711517911e-62)\n",
      "(-0.2409826395637174, 1.1173542410793628e-14)\n",
      "(0.42382627433454756, 7.316994623789752e-45)\n",
      "(-0.02513200621041742, 0.42726808486322904)\n",
      "(0.9999999999999998, 0.0)\n",
      "(-0.4323994844347462, 8.088613416041817e-47)\n",
      "(0.811826219063978, 1.98485382617195e-235)\n",
      "(-0.4065611459916171, 4.3324771825090337e-41)\n",
      "(0.7598699803870709, 7.224406460006014e-189)\n",
      "(-0.4767176424614662, 7.100434617194734e-58)\n",
      "(0.6631655625565879, 1.0179487581395835e-127)\n",
      "(-0.4581340582034286, 4.859804352176964e-53)\n",
      "(0.561007475659851, 5.591759656602743e-84)\n",
      "(-0.40110579098473187, 6.073940828451615e-40)\n",
      "(0.388223592502408, 2.557355179977131e-37)\n",
      "(-0.3283255785096091, 1.4576308398700279e-26)\n",
      "(0.21001468039737328, 1.9746317064319454e-11)\n",
      "(1.0, 0.0)\n",
      "(-0.37886809421152273, 1.7450103583939707e-35)\n",
      "(0.7157774170836343, 8.293172341689876e-158)\n",
      "(-0.3437618116856036, 4.067608454195702e-29)\n",
      "(0.6741489620580421, 1.7489624932685222e-133)\n",
      "(-0.24413471052880342, 4.904872183363445e-15)\n",
      "(0.6472447116648878, 8.753728923089365e-120)\n",
      "(-0.19625763467522755, 3.864137402267771e-10)\n",
      "(0.556023249559648, 3.198796509366165e-82)\n",
      "(-0.095909058485435, 0.0023964492956485423)\n",
      "(0.41714722694364353, 2.23812508897326e-43)\n",
      "(0.04121960231968364, 0.1927791619344503)\n",
      "(0.9999999999999999, 0.0)\n",
      "(-0.3463073090361787, 1.4930425422988813e-29)\n",
      "(0.80801317954804, 1.551129389916356e-231)\n",
      "(-0.42327748368018436, 9.719859805465479e-45)\n",
      "(0.6989180048012847, 1.892915030464397e-147)\n",
      "(-0.3624414569962268, 2.0908560090870998e-32)\n",
      "(0.603696665024078, 2.46899228468608e-100)\n",
      "(-0.287155826429918, 1.9484218413659772e-20)\n",
      "(0.5028899063243699, 3.281060445630209e-65)\n",
      "(-0.22767110762409448, 3.1814237437313215e-13)\n",
      "(0.33350220809094533, 2.1047381669598692e-27)\n",
      "(0.9999999999999999, 0.0)\n",
      "(-0.29775553163009405, 6.38230561473785e-22)\n",
      "(0.7613355650615151, 5.14815015875033e-190)\n",
      "(-0.1515373544247806, 1.4803955623807591e-06)\n",
      "(0.6536252537642987, 6.607419865915078e-123)\n",
      "(-0.17828178676192857, 1.3768187506591673e-08)\n",
      "(0.5024223938806697, 4.494740343058095e-65)\n",
      "(-0.13116877128952886, 3.1724365897916664e-05)\n",
      "(0.4418543107512625, 4.830847808864597e-49)\n",
      "(0.00483087970068934, 0.8787329265533458)\n",
      "(1.0, 0.0)\n",
      "(-0.3586978245707844, 9.936998768682408e-32)\n",
      "(0.7346503141575594, 2.4436762054514026e-170)\n",
      "(-0.3566583930311798, 2.302733435583022e-31)\n",
      "(0.6125536853917406, 4.803238577572681e-104)\n",
      "(-0.2998418549931778, 3.201311192757836e-22)\n",
      "(0.4583823859597642, 4.206794415523705e-53)\n",
      "(-0.23139930540055767, 1.2713891195604898e-13)\n",
      "(0.3865846866591947, 5.412393132192418e-37)\n",
      "(1.0, 0.0)\n",
      "(-0.17190431505197584, 4.498790972957962e-08)\n",
      "(0.733808330511648, 9.330158928531352e-170)\n",
      "(-0.16663196580487138, 1.158852878963448e-07)\n",
      "(0.5672127608974892, 3.291621319188023e-86)\n",
      "(-0.21309431016638447, 9.858441825227522e-12)\n",
      "(0.45875305018288187, 3.390900025496462e-53)\n",
      "(-0.016692523225714108, 0.5980266172659198)\n",
      "(1.0, 0.0)\n",
      "(-0.11734907071239523, 0.000199918977514417)\n",
      "(0.6599513393442424, 4.4541975943407904e-126)\n",
      "(-0.10373999938177966, 0.0010186966263175728)\n",
      "(0.47565909762640196, 1.3639110446268274e-57)\n",
      "(-0.1221308442874094, 0.00010803974600342387)\n",
      "(0.382340631696858, 3.698316418580378e-36)\n",
      "(1.0, 0.0)\n",
      "(-0.03224409293729854, 0.30837517914959306)\n",
      "(0.6752241675259604, 4.62340391424293e-134)\n",
      "(-0.024606110900838984, 0.4370065533683837)\n",
      "(0.4444073059536685, 1.1786715132561639e-49)\n",
      "(-0.03352805240452866, 0.2894987636213012)\n",
      "(0.9999999999999999, 0.0)\n",
      "(0.0687155451676031, 0.02979332274850619)\n",
      "(0.5937945320266359, 2.5451111670298952e-96)\n",
      "(-0.0052642915820911625, 0.8679488339143026)\n",
      "(0.40839338159034405, 1.765171009366385e-41)\n",
      "(1.0, 0.0)\n",
      "(0.17063421385767055, 5.6657627684967606e-08)\n",
      "(0.5549181043363228, 7.773984348746307e-82)\n",
      "(0.11769961371875962, 0.00019124714968928215)\n",
      "(0.9999999999999999, 0.0)\n",
      "(0.18982384880338574, 1.4453932661833113e-09)\n",
      "(0.44897344357508623, 9.174592757727421e-51)\n",
      "(0.9999999999999997, 0.0)\n",
      "(0.33955504729143515, 2.088733299621549e-28)\n",
      "(0.9999999999999996, 0.0)\n"
     ]
    }
   ],
   "source": [
    "upperBound = data.shape[1] - 1\n",
    "corrPairs = [0 for i in range(upperBound - 1)]\n",
    "for i in range(1, upperBound):\n",
    "    for j in range(i + 1, upperBound):\n",
    "        corr = sp.stats.pearsonr(data.iloc[:, i], data.iloc[:, j])\n",
    "        if (corr[0]) > 0.7:\n",
    "            corrPairs[i] += 1\n",
    "            corrPairs[j] += 1\n",
    "print(corrPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the raw data into labels and features for the testing & training sets\n",
    "rawData = data.values.tolist()\n",
    "\n",
    "#Shuffle the data so it's random\n",
    "rd.shuffle(rawData)\n",
    "\n",
    "#Get the labels and relevant features\n",
    "allLabels = [None] * len(rawData)\n",
    "allFeatures = [None] * len(rawData)\n",
    "\n",
    "#Label is column #30, index 29\n",
    "for i in range(len(allLabels)):\n",
    "    allLabels[i] = rawData[i][29]\n",
    "\n",
    "#Need to convert them to ints\n",
    "for i in range(len(allLabels)):\n",
    "    label = allLabels[i]\n",
    "    if(label == \"blues\"):\n",
    "        allLabels[i] = 0\n",
    "    elif(label == \"classical\"):\n",
    "        allLabels[i] = 1\n",
    "    elif(label == \"country\"):\n",
    "        allLabels[i] = 2\n",
    "    elif(label == \"disco\"):\n",
    "        allLabels[i] = 3\n",
    "    elif(label == \"hiphop\"):\n",
    "        allLabels[i] = 4\n",
    "    elif(label == \"jazz\"):\n",
    "        allLabels[i] = 5\n",
    "    elif(label == \"metal\"):\n",
    "        allLabels[i] = 6\n",
    "    elif(label == \"pop\"):\n",
    "        allLabels[i] = 7\n",
    "    elif(label == \"reggae\"):\n",
    "        allLabels[i] = 8\n",
    "    elif(label == \"rock\"):\n",
    "        allLabels[i] = 9\n",
    "\n",
    "#Make them the right dimensions\n",
    "allLabels = tf.keras.utils.to_categorical(allLabels)\n",
    "\n",
    "#We want the features at 3, 4, 5, 6, 7, 10, 11, 13, 15, & 17\n",
    "for i in range(len(allFeatures)):\n",
    "    rawItem = rawData[i][:]\n",
    "    item = rawItem[3:8]\n",
    "    item.append(rawItem[10])\n",
    "    item.append(rawItem[11])\n",
    "    item.append(rawItem[13])\n",
    "    item.append(rawItem[15])\n",
    "    item.append(rawItem[17])\n",
    "    allFeatures[i] = item\n",
    "\n",
    "#Make it the right type\n",
    "#allFeatures = np.expand_dims(allFeatures, axis=-1)\n",
    "\n",
    "#Determine how many elements the test set should contain\n",
    "testSize = round(len(rawData) * 0.2)\n",
    "\n",
    "#Split the sets\n",
    "testFeatures = np.asarray(allFeatures[:testSize])\n",
    "testLabels = np.asarray(allLabels[:testSize])\n",
    "trainFeatures = np.asarray(allFeatures[testSize:])\n",
    "trainLabels = np.asarray(allLabels[testSize:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "mlpModel = models.Sequential()\n",
    "mlpModel.add(layers.Dense(20, activation='relu', input_shape = (10,)))\n",
    "mlpModel.add(layers.Dense(60))\n",
    "mlpModel.add(layers.Dense(120))\n",
    "mlpModel.add(layers.Dense(30))\n",
    "mlpModel.add(layers.Dense(10))\n",
    "mlpModel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "#mlpModel.build()\n",
    "#mlpModel.summary()\n",
    "history = mlpModel.fit(trainFeatures, trainLabels, epochs=10, shuffle=True, validation_data=(testFeatures, testLabels))\n",
    "mlpModel.fit(trainFeatures, trainLabels, epochs=10, shuffle=True, validation_data=(testFeatures, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printConf(acc, labels, clusters=10):\n",
    "    for i in range(clusters):\n",
    "        for j in acc[i]:\n",
    "            print(f\"{j}\\t\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    for i in range(clusters):\n",
    "        print(f\"Cluster value for label {i}: {labels[i]}\")\n",
    "\n",
    "\n",
    "def defLabels(acc):\n",
    "    labels = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9:[]}\n",
    "    for key, val in acc.items():\n",
    "        for i in range(len(val)):\n",
    "            if val[i] == max(val):\n",
    "                labels[key].append(i)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "# K-Means Classification\n",
    "def kMeans(x, y):\n",
    "    # Array for accuracy counts\n",
    "    acc = {}\n",
    "    kmeans = skc.KMeans(n_clusters=10, n_init=100, max_iter=1000, verbose=0).fit(x)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if y[i] not in acc:\n",
    "            acc[y[i]] = [0 for i in range(10)]\n",
    "        acc[y[i]][kmeans.labels_[i]] += 1\n",
    "    \n",
    "    return acc\n",
    "\n",
    "acc = kMeans(x, y)\n",
    "labels = defLabels(acc)\n",
    "printConf(acc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ART\n",
    "#Create a new starting model\n",
    "def createModel():\n",
    "    newModel = models.Sequential()\n",
    "    newModel.add(layers.Dense(1, input_shape = (10,), kernel_initializer = \"random_normal\"))\n",
    "    newModel.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return newModel\n",
    "\n",
    "#Make a list of models to compete with each other\n",
    "modelList = []\n",
    "\n",
    "#Make the first model\n",
    "modelList.append(createModel())\n",
    "\n",
    "#Evaluate the first input, training the model on it\n",
    "centroids = []\n",
    "clusters = []\n",
    "output = modelList[0](np.asarray([trainFeatures[0]]))\n",
    "centroids.append(tf.keras.backend.get_value(output[0][0]))\n",
    "clusters.append([0])\n",
    "modelList[0].fit(np.asarray([trainFeatures[0]]), np.asarray([centroids[0]])) #Not sure if you can feed it a lable like this\n",
    "\n",
    "#Do this for every input\n",
    "vigilance = 500\n",
    "for i in range(1, len(trainFeatures)):\n",
    "    currentFeature = trainFeatures[i]\n",
    "    foundModel = False\n",
    "\n",
    "    #Find the best model for evaluating the current input\n",
    "    minDistance = float('inf')\n",
    "    bestModel = None\n",
    "    bestModelIndex = -1\n",
    "    for j in range(len(modelList)):\n",
    "        currentModel = modelList[j]\n",
    "\n",
    "        #Get an output\n",
    "        output = currentModel(np.asarray([currentFeature]))\n",
    "        output = tf.keras.backend.get_value(output[0][0])\n",
    "\n",
    "        #Check if the distance between the output and the centroid is the lowest found\n",
    "        if(abs(output - centroids[j]) < minDistance):\n",
    "            minDistance = abs(output - centroids[j])\n",
    "            bestModel = currentModel\n",
    "            bestModelIndex = j\n",
    "\n",
    "    #Check if the best model is close enough according to the vigilance\n",
    "    if(minDistance < vigilance):\n",
    "        #Update the centroid and cluster\n",
    "        centroids[bestModelIndex] = ((centroids[bestModelIndex] * len(clusters[bestModelIndex])) + output) / (len(clusters[bestModelIndex]) + 1)\n",
    "        clusters[bestModelIndex].append(i)\n",
    "\n",
    "        #Train the model on the input\n",
    "        bestModel.fit(np.asarray([currentFeature]), np.asarray([centroids[bestModelIndex]]))\n",
    "\n",
    "    #If it's not, make a new model for the unhandled value\n",
    "    else:\n",
    "        print(\"making new model\")\n",
    "\n",
    "        #Get the output from the new model\n",
    "        newModel = createModel()\n",
    "        output = newModel(np.asarray([currentFeature]))\n",
    "\n",
    "        #Make new entries for the model\n",
    "        modelList.append(newModel)\n",
    "        centroids.append(tf.keras.backend.get_value(output[0][0]))\n",
    "        clusters.append([i])\n",
    "\n",
    "        #Train the model on it's new centroid\n",
    "        newModel.fit(np.asarray([currentFeature]), np.asarray([tf.keras.backend.get_value(output[0][0])]))\n",
    "\n",
    "print(str(len(modelList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative ART\n",
    "#Make the model\n",
    "artModel = models.Sequential()\n",
    "artModel.add(layers.Dense(1, input_shape = (10,), kernel_initializer = \"random_normal\"))\n",
    "artModel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "#Start the list of centroids & clusters\n",
    "centroids = []\n",
    "clusters = []\n",
    "\n",
    "#Loop through every input\n",
    "vigilance = 600\n",
    "for i in range(1, len(x_train)):\n",
    "    currentFeature = x_train[i]\n",
    "\n",
    "    #Get the output from the network \n",
    "    output = artModel(np.asarray([currentFeature]))\n",
    "    output = tf.keras.backend.get_value(output[0][0])\n",
    "\n",
    "    #Find the closest centroid\n",
    "    minDistance = float('inf')\n",
    "    bestClusterIndex = -1\n",
    "    for j in range(len(centroids)):\n",
    "        dist = abs(centroids[j] - output)\n",
    "        if(dist < minDistance):\n",
    "            minDistance = dist\n",
    "            bestClusterIndex = j\n",
    "\n",
    "    #Put the input in that cluster, if it's within vigilance distance\n",
    "    if(minDistance < vigilance):\n",
    "        centroids[bestClusterIndex] = ((centroids[bestClusterIndex] * len(clusters[bestClusterIndex])) + output) / (len(clusters[bestClusterIndex]) + 1)\n",
    "        clusters[bestClusterIndex].append(i)\n",
    "\n",
    "        #Also train the model on that centroid & input\n",
    "        artModel.fit(np.asarray([currentFeature]), np.asarray([centroids[bestClusterIndex]]))\n",
    "\n",
    "    #If it's not within the vigilance distance, make a new cluster\n",
    "    else:\n",
    "        print(\"Making new cluster\")\n",
    "        centroids.append(output)\n",
    "        clusters.append([i])\n",
    "        artModel.fit(np.asarray([currentFeature]), np.asarray([output]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ART printout\n",
    "print(\"Printing \" + str(len(clusters)) + \" clusters\")\n",
    "\n",
    "#Initialize the cluster count list\n",
    "clusterCounts = [[0 for i in range(10)] for i in range(len(clusters))]\n",
    "\n",
    "#For each cluster, count the occurances of each label\n",
    "for i in range(len(clusters)):\n",
    "    for labelIndex in clusters[i]:\n",
    "        clusterCounts[i][np.argmax(trainLabels[labelIndex])] += 1\n",
    "\n",
    "for count in clusterCounts:\n",
    "    print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f2f02e1de8357b716a172ad62847c46880f415b272f7ede03f31fa82ee7994b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
