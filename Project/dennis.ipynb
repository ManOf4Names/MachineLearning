{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import sklearn.cluster as skc\n",
    "import sklearn.neighbors as skn\n",
    "import sklearn.feature_selection as skf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kicked Tensorflow to it's own cell so I can work on K-Means at work\n",
    "import tensorflow as tf\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/data.csv', header=0)\n",
    "genreKey = {\"blues\": 0,\n",
    "            \"classical\": 1,\n",
    "            \"country\": 2,\n",
    "            \"disco\": 3,\n",
    "            \"hiphop\": 4,\n",
    "            \"jazz\": 5,\n",
    "            \"metal\": 6,\n",
    "            \"pop\": 7,\n",
    "            \"reggae\": 8,\n",
    "            \"rock\": 9}\n",
    "\n",
    "def dimReduce(data, dims=10):\n",
    "    # Select Data\n",
    "    X = np.array(data.iloc[:, 1:29])\n",
    "    y = np.array(data.iloc[:, 29])\n",
    "    # Make the feature selection model with ANOVA F Measure\n",
    "    fs = skf.SelectKBest(score_func=skf.f_classif, k=dims)\n",
    "    # Run the data through selection to obtain final set\n",
    "    X_sel = fs.fit_transform(X, y)\n",
    "\n",
    "    return X_sel, y\n",
    "\n",
    "def prepData(data, key, split=0.2, dims= 10, doSplit=True):\n",
    "    # Reduce the dimensionality of the dataset to a set number of features\n",
    "    x, y = dimReduce(data, dims)\n",
    "    # Define the number of elements in the test set\n",
    "    splitRange = int(len(data) * split)\n",
    "    # Create and randomize an array representing data ordering\n",
    "    rand = [i for i in range(len(data))]\n",
    "    rd.shuffle(rand)\n",
    "    # Create Testing and training arrays\n",
    "    x_train = np.array([])\n",
    "    y_train = np.array([])\n",
    "    x_test = np.array([])\n",
    "    y_test = np.array([])\n",
    "\n",
    "    if (doSplit):\n",
    "        # Populate test arrays with a random split% of the whole set\n",
    "        for i in range(splitRange):\n",
    "            # Set the dimensions of the x_test array\n",
    "            if x_test.ndim == 1:\n",
    "                x_test = np.array([x[rand[i]]])\n",
    "            # Append further elements to the existing array\n",
    "            else:\n",
    "                x_test = np.append(x_test, [x[rand[i]]], 0)\n",
    "            # Add label in integer form\n",
    "            y_test = np.append(y_test, key[y[rand[i]]])\n",
    "            \n",
    "        for i in range(splitRange, len(data)):\n",
    "            # Set the dimensions of the x_train array\n",
    "            if x_train.ndim == 1:\n",
    "                x_train = np.array([x[rand[i]]])\n",
    "            # Append further elements to the existing array\n",
    "            else:\n",
    "                x_train = np.append(x_train, [x[rand[i]]], 0)\n",
    "            # Add label in integer form\n",
    "            y_train = np.append(y_train, key[y[rand[i]]])\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            # Add label in integer form\n",
    "            y[i] = key[yrand[i]]\n",
    "        return x, y\n",
    "\n",
    "def normalize(data):\n",
    "    # Array for the max value of each feature. Used in normalization\n",
    "    normax = []\n",
    "    # Array for the min value of each feature. Used to eliminate negatives\n",
    "    normin = []\n",
    "\n",
    "    # Populate max and min arrays\n",
    "    for i in range(data.shape[1]):\n",
    "        normin.append(min(data[:, i]))\n",
    "        normax.append(max(data[:, i]) - normin[i])\n",
    "\n",
    "    # Normalize each vector in the dataset\n",
    "    for i in data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = (i[j] - normin[j]) / normax[j]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Split the dataset into test and training sets.\n",
    "# x_train, y_train, x_test, y_test = prepData(data, genreKey, dims=10)\n",
    "# x_train = normalize(x_train)\n",
    "# x_test = normalize(x_test)\n",
    "\n",
    "# Unsplit Data for K-Means\n",
    "x, y = prepData(data, genreKey, doSplit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the raw data into labels and features for the testing & training sets\n",
    "rawData = data.values.tolist()\n",
    "\n",
    "#Shuffle the data so it's random\n",
    "rd.shuffle(rawData)\n",
    "\n",
    "#Get the labels and relevant features\n",
    "allLabels = [None] * len(rawData)\n",
    "allFeatures = [None] * len(rawData)\n",
    "\n",
    "#Label is column #30, index 29\n",
    "for i in range(len(allLabels)):\n",
    "    allLabels[i] = rawData[i][29]\n",
    "\n",
    "#Need to convert them to ints\n",
    "for i in range(len(allLabels)):\n",
    "    label = allLabels[i]\n",
    "    if(label == \"blues\"):\n",
    "        allLabels[i] = 0\n",
    "    elif(label == \"classical\"):\n",
    "        allLabels[i] = 1\n",
    "    elif(label == \"country\"):\n",
    "        allLabels[i] = 2\n",
    "    elif(label == \"disco\"):\n",
    "        allLabels[i] = 3\n",
    "    elif(label == \"hiphop\"):\n",
    "        allLabels[i] = 4\n",
    "    elif(label == \"jazz\"):\n",
    "        allLabels[i] = 5\n",
    "    elif(label == \"metal\"):\n",
    "        allLabels[i] = 6\n",
    "    elif(label == \"pop\"):\n",
    "        allLabels[i] = 7\n",
    "    elif(label == \"reggae\"):\n",
    "        allLabels[i] = 8\n",
    "    elif(label == \"rock\"):\n",
    "        allLabels[i] = 9\n",
    "\n",
    "#Make them the right dimensions\n",
    "allLabels = tf.keras.utils.to_categorical(allLabels)\n",
    "\n",
    "#We want the features at 3, 4, 5, 6, 7, 10, 11, 13, 15, & 17\n",
    "for i in range(len(allFeatures)):\n",
    "    rawItem = rawData[i][:]\n",
    "    item = rawItem[3:8]\n",
    "    item.append(rawItem[10])\n",
    "    item.append(rawItem[11])\n",
    "    item.append(rawItem[13])\n",
    "    item.append(rawItem[15])\n",
    "    item.append(rawItem[17])\n",
    "    allFeatures[i] = item\n",
    "\n",
    "#Make it the right type\n",
    "#allFeatures = np.expand_dims(allFeatures, axis=-1)\n",
    "\n",
    "#Determine how many elements the test set should contain\n",
    "testSize = round(len(rawData) * 0.2)\n",
    "\n",
    "#Split the sets\n",
    "testFeatures = np.asarray(allFeatures[:testSize])\n",
    "testLabels = np.asarray(allLabels[:testSize])\n",
    "trainFeatures = np.asarray(allFeatures[testSize:])\n",
    "trainLabels = np.asarray(allLabels[testSize:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "mlpModel = models.Sequential()\n",
    "mlpModel.add(layers.Dense(20, activation='relu', input_shape = (10,)))\n",
    "mlpModel.add(layers.Dense(60))\n",
    "mlpModel.add(layers.Dense(120))\n",
    "mlpModel.add(layers.Dense(30))\n",
    "mlpModel.add(layers.Dense(10))\n",
    "mlpModel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "#mlpModel.build()\n",
    "#mlpModel.summary()\n",
    "history = mlpModel.fit(trainFeatures, trainLabels, epochs=10, shuffle=True, validation_data=(testFeatures, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues' 'blues'\n",
      " 'blues' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'classical'\n",
      " 'classical' 'classical' 'classical' 'classical' 'classical' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'country' 'country' 'country' 'country' 'country' 'country'\n",
      " 'country' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco' 'disco'\n",
      " 'disco' 'disco' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop'\n",
      " 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'hiphop' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz'\n",
      " 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'jazz' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal'\n",
      " 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'metal' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop' 'pop'\n",
      " 'pop' 'pop' 'pop' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae'\n",
      " 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'reggae' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock'\n",
      " 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock' 'rock']\n",
      "[5 3 9 9 0 5 4 0 3 3 8 3 4 3 9 1 4 0 3 0 4 9 0 4 9 4 5 4 1 9 9 4 5 4 0 9 5\n",
      " 4 5 3 0 0 9 3 5 4 9 0 9 3 4 8 0 0 4 3 3 0 1 9 4 5 9 4 9 3 9 1 4 8 3 1 3 3\n",
      " 4 3 9 4 9 0 8 1 9 5 0 3 4 1 3 0 0 3 9 9 9 5 0 1 5 4 5 9 3 9 3 8 3 3 9 0 9\n",
      " 8 3 0 3 3 8 3 3 8 5 3 3 9 8 9 0 8 9 9 9 8 3 8 3 3 9 3 3 8 3 9 5 8 8 3 3 9\n",
      " 9 3 9 3 3 3 3 3 4 3 0 3 8 3 3 9 3 3 9 9 8 0 9 3 5 9 9 8 3 3 9 3 9 3 9 3 3\n",
      " 3 3 9 3 3 3 8 8 9 8 3 3 3 9 8 7 4 7 4 0 7 9 9 7 3 4 9 9 4 2 9 0 5 9 1 0 7\n",
      " 5 6 4 5 0 3 7 1 0 0 0 7 5 8 9 9 0 5 0 4 5 5 5 4 0 9 9 3 9 4 3 9 2 5 1 1 7\n",
      " 5 9 3 3 5 9 5 9 9 7 9 9 5 1 9 9 3 3 0 9 0 5 3 3 4 9 4 9 8 0 9 3 0 0 5 0 0\n",
      " 0 8 7 9 7 1 7 7 1 2 1 4 4 5 2 7 4 1 2 2 4 4 2 6 1 7 5 6 5 1 1 5 1 1 2 4 5\n",
      " 1 2 4 4 5 4 4 6 4 4 1 1 7 5 6 0 5 4 1 5 4 4 2 9 6 4 1 4 4 1 7 1 7 4 7 1 0\n",
      " 4 5 2 7 4 5 2 4 2 4 4 7 5 1 2 4 4 7 4 0 1 7 2 4 1 6 1 5 7 4 7 1 4 1 2 5 7\n",
      " 7 9 4 7 2 7 4 7 5 1 2 1 6 7 7 1 4 1 1 4 5 1 5 2 1 4 7 1 0 2 1 7 4 4 1 2 7\n",
      " 1 9 4 1 4 2 1 4 4 4 7 1 2 0 1 4 1 7 5 5 1 0 4 0 0 1 2 5 1 5 0 7 1 1 7 5 4\n",
      " 0 1 4 0 7 4 0 1 5 6 2 7 1 4 1 4 5 7 4 8 9 9 0 2 5 7 1 9 5 9 3 0 4 0 3 5 0\n",
      " 5 8 9 7 8 5 1 6 9 9 0 5 7 0 2 5 7 9 9 5 8 8 9 9 0 8 0 8 5 9 4 9 2 9 3 6 1\n",
      " 9 9 9 9 4 3 1 1 4 0 3 1 3 5 0 3 3 3 7 5 3 0 3 0 7 8 7 3 0 7 0 0 0 9 3 3 5\n",
      " 3 8 1 0 8 3 3 0 5 1 5 1 1 7 1 4 4 4 4 5 4 1 1 7 4 4 4 1 1 2 7 4 4 1 1 4 5\n",
      " 5 7 4 5 4 1 1 1 7 4 0 7 1 1 4 4 5 4 5 4 1 2 1 5 5 1 1 1 9 7 4 5 1 4 1 4 1\n",
      " 1 0 7 1 4 5 1 1 4 7 4 1 1 4 1 4 1 4 1 1 7 1 5 1 1 7 4 4 1 1 5 5 1 1 2 2 2\n",
      " 2 2 2 5 6 7 0 6 7 1 6 4 1 6 1 2 6 6 7 2 7 1 2 6 6 6 2 7 1 2 6 2 4 6 2 6 2\n",
      " 6 2 7 6 2 6 2 5 5 6 4 2 2 6 6 7 7 6 2 6 4 2 2 2 2 7 2 2 6 2 7 6 6 4 6 6 6\n",
      " 2 4 5 2 6 2 6 7 1 2 5 7 6 2 1 6 6 2 0 7 5 0 2 9 1 1 4 1 9 5 0 1 5 0 4 4 4\n",
      " 5 0 7 2 0 5 0 4 5 1 4 4 4 4 1 0 9 0 4 1 6 9 5 5 9 0 9 4 9 0 4 0 7 4 5 4 0\n",
      " 0 1 0 5 2 1 5 4 1 4 0 0 0 2 5 1 9 6 0 4 5 0 0 1 4 0 6 5 7 5 1 0 7 0 0 5 1\n",
      " 0 0 2 4 5 3 3 0 6 4 5 0 4 4 4 1 5 0 9 4 1 1 0 4 4 4 4 9 4 5 0 0 1 4 5 2 9\n",
      " 9 3 5 4 9 7 0 7 1 7 4 4 5 5 4 0 5 5 9 5 2 5 4 5 5 2 4 4 4 1 1 0 4 4 2 5 5\n",
      " 7 1 7 5 4 0 0 0 4 1 0 5 7 4 5 4 0 0 9 7 5 7 5 1 0 7 9 4 6 1 1 4 4 5 4 9 9\n",
      " 5]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7260/1268970659.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7260/1268970659.py\u001b[0m in \u001b[0;36mkMeans\u001b[1;34m(train, labels)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# K-Means Classification\n",
    "def kMeans(train, labels):\n",
    "    kmeans = skc.KMeans(n_clusters=10, n_init=100, max_iter=1000, verbose=0).fit(train)\n",
    "    print(labels)\n",
    "    print(kmeans.labels_)\n",
    "\n",
    "kMeans(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e9548d0f655117a047e388695746c0ee220d22be9f30de4f4d8bfc50335b506"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
